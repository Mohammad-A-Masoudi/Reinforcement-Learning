import numpy as np
class NeuralNetwork():
    def __init__(self):
        self.inputlayersize = 2
        self.hiddenlayersize= 3
        self.outputlayersize = 1
        
        self.w1 = np.random.randn(self.inputlayersize, self.hiddenlayersize)
        self.w2 = np.random.randn(self.hiddenlayersize, self.outputlayersize)
    def sigmoid(self, z):
        return 1/(1 +np.exp(-z))
    
    def forward(self,X):
        self.z2 = np.dot(X,self.w1)
        self.a2 = self.sigmoid(self.z2)
        self.z3 = np.dot(self.a2, self.w2)
        y_hat = self.sigmoid(self.z3)
        return y_hat
        
    def cost(self, X, y):
        y_hat = self.forward(X)
        j = 0.5 *sum((y-self.y_hat)**2)
        return j
        
    def sigmoid_prime(self, z):
        return self.sigmoid(z) * (1- self.sigmoid(z))
    
    def cost_prime(self, X, y):
        self.y_hat = self.forward(X)
        delta3 = np.multiply(-(y-self.y_hat),self.sigmoid_prime(self.z3))
        djdw2 = np.dot(self.a2.T,delta3)
        delta2 = np.dot(delta3, self.w2.T)* self.sigmoid_prime(self.z2)
        djdw1 = np.dot(X.T,delta2)
        
        return djdw1, djdw2
        
X = np.random.rand(1000,2)
y =np.apply_along_axis(lambda element : element[0]+ element[1], axis =1 , arr =X)
y.shape = (1000,1)
net = NeuralNetwork()
lr = 0.01
max_iteration = 10000
for iteration in range(max_iteration):
    dJw1 , dJw2 = net.cost_prime(X, y)
    net.w1 = net.w1 - lr*dJw1
    net.w2 = net.w2 - lr*dJw2
    
    if iteration % 1000 == 0:
        print(net.cost(X,y))


        
        
        
        
        
        
#net = NeuralNetwork()        
#print(net.W1, net.W2)        
    
